# TRG-DQA: Texture Residual-guided dehazed image quality assessment

**by [Tiantian Zeng](https://scholar.google.com.hk/citations?user=gemAtrkAAAAJ&hl=zh-CN), [Lu Zhang](https://scholar.google.com.hk/citations?hl=zh-CN&user=BCzhwesAAAAJ&view_op=list_works&sortby=pubdate), [Wenbin Zou](https://scholar.google.com.hk/citations?user=J8-OQCIAAAAJ&hl=zh-CN), Xia Li, and [Shishun Tian](https://scholar.google.com.hk/citations?user=gk8puWMAAAAJ&hl=zh-CN)**

**[[ICIP2023 Paper]](https://ieeexplore.ieee.org/abstract/document/10222233)**

## Abstract

_Image dehazing algorithms have emerged to solve the visual impairment caused by haze. It is important to establish dehazed image quality assessment (DQA) methods that can accurately evaluate the dehazed image quality and the performance of dehazing algorithms. However, classical image quality assessment (IQA) and most hand-crafted feature based DQA methods may not be able to adequately measure complex distortions of dehazed images. To address this issue, this paper proposes a Texture Residual-Guided Dehazed image Quality Assessment (TRG-DQA) method. Specifically, we first introduce a global and local feature extraction module employing a combination of the Transformer and convolutional neural networks (CNN) for extracting the comprehensive features. Considering that texture residual maps represent haze density and artifact distortion information, we propose a residual-guided module to guide the model for efficient learning. Additionally, to mitigate the information loss issue that occurs in deeper networks, a distortion-aware feature enhancement module is proposed. Extensive experiments on six DQA databases demonstrate the proposed TRG-DQA achieves superior performance among all the state-of-the-art methods._

